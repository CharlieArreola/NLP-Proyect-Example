{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "<h1>Data Wrangling: Natural Language Processing<h1>\n<h3>  Objective:</h3> <p>Here we will be generating some tokens on the content for every review. For NLP processe's we'll be using spacy and for Sentiment Analysis some Transformers</p>\n<bh>\n\n"}, {"metadata": {}, "cell_type": "code", "source": "import numpy as np\nimport types\nimport pandas as pd\nimport nltk\nfrom dateutil import parser\nnltk.download('gutenberg')\nnltk.download('genesis')\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\n", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "[nltk_data] Downloading package gutenberg to\n[nltk_data]     /home/spark/shared/nltk_data...\n[nltk_data]   Package gutenberg is already up-to-date!\n[nltk_data] Downloading package genesis to\n[nltk_data]     /home/spark/shared/nltk_data...\n[nltk_data]   Package genesis is already up-to-date!\n", "name": "stderr"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Data Load"}, {"metadata": {}, "cell_type": "code", "source": "import os, types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\nclient_03c3f449e3a74b8da664e49bfbd86b7e = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='XrKG-mLlaOOc0yOuhimgI7ltLGZu6MlvR-HNPdLjKNRt',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3.private.us.cloud-object-storage.appdomain.cloud')\n\nstreaming_body_1 = client_03c3f449e3a74b8da664e49bfbd86b7e.get_object(Bucket='personal-donotdelete-pr-em2zsfdcmhl7q5', Key='AmazonReviewsData.tsv')['Body']\n\n# Your data file was loaded into a botocore.response.StreamingBody object.\n# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n# pandas documentation: http://pandas.pydata.org/\nstreaming_body_1", "execution_count": 2, "outputs": [{"output_type": "execute_result", "execution_count": 2, "data": {"text/plain": "<ibm_botocore.response.StreamingBody at 0x7f0b5b142f70>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "from io import StringIO\nfrom io import BytesIO\na=streaming_body_1.read()\ndf = pd.read_csv(BytesIO(a),sep='|', header=[0])\ndf.head(5)", "execution_count": 3, "outputs": [{"output_type": "execute_result", "execution_count": 3, "data": {"text/plain": "  Review Author                                     Review Content  Stars\n0        Sydney  Tolles Halsband super gut verarbeitet und die ...    0.0\n1        Sydney  Tolles Halsband super gut verarbeitet und die ...    0.0\n2  Carmen Heger  Ich bin total verliebt in diese Halsbander. Mi...    0.0\n3        Sydney  Tolles Halsband super gut verarbeitet und die ...    0.0\n4  Carmen Heger  Ich bin total verliebt in diese Halsbander. Mi...    0.0", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Review Author</th>\n      <th>Review Content</th>\n      <th>Stars</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Sydney</td>\n      <td>Tolles Halsband super gut verarbeitet und die ...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sydney</td>\n      <td>Tolles Halsband super gut verarbeitet und die ...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Carmen Heger</td>\n      <td>Ich bin total verliebt in diese Halsbander. Mi...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Sydney</td>\n      <td>Tolles Halsband super gut verarbeitet und die ...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Carmen Heger</td>\n      <td>Ich bin total verliebt in diese Halsbander. Mi...</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "## NLP Exploration"}, {"metadata": {}, "cell_type": "code", "source": "# Lets start with an overview\ndf['Review Content'].head(10)", "execution_count": 4, "outputs": [{"output_type": "execute_result", "execution_count": 4, "data": {"text/plain": "0    Tolles Halsband super gut verarbeitet und die ...\n1    Tolles Halsband super gut verarbeitet und die ...\n2    Ich bin total verliebt in diese Halsbander. Mi...\n3    Tolles Halsband super gut verarbeitet und die ...\n4    Ich bin total verliebt in diese Halsbander. Mi...\n5    Sehr susses Halsband, werde oft darauf angespr...\n6    Tolles Halsband super gut verarbeitet und die ...\n7    Ich bin total verliebt in diese Halsbander. Mi...\n8    Sehr susses Halsband, werde oft darauf angespr...\n9                          entspricht der Beschreibung\nName: Review Content, dtype: object"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "\ndf['Review Content_nword'] = df['Review Content'].apply(lambda x: len(str(x).split(\" \")))\ndf[[\"Review Content\",\"Review Content_nword\"]].sort_values(by = \"Review Content_nword\",ascending = True).head(5)\n", "execution_count": 5, "outputs": [{"output_type": "execute_result", "execution_count": 5, "data": {"text/plain": "     Review Content  Review Content_nword\n5719            NaN                     1\n2851            NaN                     1\n2863            NaN                     1\n5689            NaN                     1\n5698            NaN                     1", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Review Content</th>\n      <th>Review Content_nword</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5719</th>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2851</th>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2863</th>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5689</th>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5698</th>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "\ndf[[\"Review Content\",\"Review Content_nword\"]].sort_values(by = \"Review Content_nword\",ascending = False).head(10)\n", "execution_count": 6, "outputs": [{"output_type": "execute_result", "execution_count": 6, "data": {"text/plain": "                                         Review Content  Review Content_nword\n3808  Having a small dog (Yorkshire Terrier) doesnt ...                  1033\n1428  Having a small dog (Yorkshire Terrier) doesnt ...                  1033\n436   Having a small dog (Yorkshire Terrier) doesnt ...                  1033\n4059  We've had this collar for over three months no...                   625\n1677  We've had this collar for over three months no...                   625\n684   We've had this collar for over three months no...                   625\n685   We've had this collar for over three months no...                   625\n1686  We've had this collar for over three months no...                   625\n687   We've had this collar for over three months no...                   625\n690   We've had this collar for over three months no...                   625", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Review Content</th>\n      <th>Review Content_nword</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3808</th>\n      <td>Having a small dog (Yorkshire Terrier) doesnt ...</td>\n      <td>1033</td>\n    </tr>\n    <tr>\n      <th>1428</th>\n      <td>Having a small dog (Yorkshire Terrier) doesnt ...</td>\n      <td>1033</td>\n    </tr>\n    <tr>\n      <th>436</th>\n      <td>Having a small dog (Yorkshire Terrier) doesnt ...</td>\n      <td>1033</td>\n    </tr>\n    <tr>\n      <th>4059</th>\n      <td>We've had this collar for over three months no...</td>\n      <td>625</td>\n    </tr>\n    <tr>\n      <th>1677</th>\n      <td>We've had this collar for over three months no...</td>\n      <td>625</td>\n    </tr>\n    <tr>\n      <th>684</th>\n      <td>We've had this collar for over three months no...</td>\n      <td>625</td>\n    </tr>\n    <tr>\n      <th>685</th>\n      <td>We've had this collar for over three months no...</td>\n      <td>625</td>\n    </tr>\n    <tr>\n      <th>1686</th>\n      <td>We've had this collar for over three months no...</td>\n      <td>625</td>\n    </tr>\n    <tr>\n      <th>687</th>\n      <td>We've had this collar for over three months no...</td>\n      <td>625</td>\n    </tr>\n    <tr>\n      <th>690</th>\n      <td>We've had this collar for over three months no...</td>\n      <td>625</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "def splitTextToTriplet(string):\n    words = str(string).split()\n    grouped_words = [' '.join(words[i: i + 512]) for i in range(0, len(words), 512)]\n    return grouped_words\ncont=[]\nfor index, row in df.iterrows():\n    if(int(row['Review Content_nword'])>512):\n        value =row['Review Content']\n        value= splitTextToTriplet(value[0])\n        cont.append(value)\n    else:\n        cont.append(row['Review Content'])\ndf['Review Content']=cont", "execution_count": 7, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\ndf[\"Review Content_nchars\"] = df[\"Review Content\"].str.len()", "execution_count": 8, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\ndf[[\"Review Content\",\"Review Content_nchars\"]].sort_values(by = \"Review Content_nchars\",ascending = False).head()", "execution_count": 9, "outputs": [{"output_type": "execute_result", "execution_count": 9, "data": {"text/plain": "                                         Review Content  Review Content_nchars\n4058  While I never thought that I'd be buying a sho...                 2434.0\n1678  While I never thought that I'd be buying a sho...                 2434.0\n1683  While I never thought that I'd be buying a sho...                 2434.0\n1687  While I never thought that I'd be buying a sho...                 2434.0\n686   While I never thought that I'd be buying a sho...                 2434.0", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Review Content</th>\n      <th>Review Content_nchars</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4058</th>\n      <td>While I never thought that I'd be buying a sho...</td>\n      <td>2434.0</td>\n    </tr>\n    <tr>\n      <th>1678</th>\n      <td>While I never thought that I'd be buying a sho...</td>\n      <td>2434.0</td>\n    </tr>\n    <tr>\n      <th>1683</th>\n      <td>While I never thought that I'd be buying a sho...</td>\n      <td>2434.0</td>\n    </tr>\n    <tr>\n      <th>1687</th>\n      <td>While I never thought that I'd be buying a sho...</td>\n      <td>2434.0</td>\n    </tr>\n    <tr>\n      <th>686</th>\n      <td>While I never thought that I'd be buying a sho...</td>\n      <td>2434.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "\ndf[[\"Review Content\",\"Review Content_nchars\"]].sort_values(by = \"Review Content_nchars\",ascending = True).head()", "execution_count": 10, "outputs": [{"output_type": "execute_result", "execution_count": 10, "data": {"text/plain": "     Review Content  Review Content_nchars\n687             [W]                    1.0\n642             [M]                    1.0\n641             [M]                    1.0\n2968            [U]                    1.0\n1205            [W]                    1.0", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Review Content</th>\n      <th>Review Content_nchars</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>687</th>\n      <td>[W]</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>642</th>\n      <td>[M]</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>641</th>\n      <td>[M]</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2968</th>\n      <td>[U]</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1205</th>\n      <td>[W]</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "stop = ['de', 'la', 'que', 'el', 'en', 'y', 'a', 'los', 'del', 'se', 'las', 'por', 'un', 'para', 'con', 'no', 'una', 'su', 'al', 'lo', 'como', 'm\u00e1s', 'pero', 'sus', 'le', 'ya', 'o', 'este', 's\u00ed', 'porque', 'esta', 'entre', 'cuando', 'muy', 'sin', 'sobre', 'tambi\u00e9n', 'me', 'hasta', 'hay', 'donde', 'quien', 'desde', 'todo', 'nos', 'durante', 'todos', 'uno', 'les', 'ni', 'contra', 'otros', 'ese', 'eso', 'ante', 'ellos', 'e', 'esto', 'm\u00ed', 'antes', 'algunos', 'qu\u00e9', 'unos', 'yo', 'otro', 'otras', 'otra', '\u00e9l', 'tanto', 'esa', 'estos', 'mucho', 'quienes', 'nada', 'muchos', 'cual', 'poco', 'ella', 'estar', 'estas', 'algunas', 'algo', 'nosotros', 'mi', 'mis', 't\u00fa', 'te', 'ti', 'tu', 'tus', 'ellas', 'nosotras', 'vosotros', 'vosotras', 'os', 'm\u00edo', 'm\u00eda', 'm\u00edos', 'm\u00edas', 'tuyo', 'tuya', 'tuyos', 'tuyas', 'suyo', 'suya', 'suyos', 'suyas', 'nuestro', 'nuestra', 'nuestros', 'nuestras', 'vuestro', 'vuestra', 'vuestros', 'vuestras', 'esos', 'esas', 'estoy', 'est\u00e1s', 'est\u00e1', 'estamos', 'est\u00e1is', 'est\u00e1n', 'est\u00e9', 'est\u00e9s', 'estemos', 'est\u00e9is', 'est\u00e9n', 'estar\u00e9', 'estar\u00e1s', 'estar\u00e1', 'estaremos', 'estar\u00e9is', 'estar\u00e1n', 'estar\u00eda', 'estar\u00edas', 'estar\u00edamos', 'estar\u00edais', 'estar\u00edan', 'estaba', 'estabas', 'est\u00e1bamos', 'estabais', 'estaban', 'estuve', 'estuviste', 'estuvo', 'estuvimos', 'estuvisteis', 'estuvieron', 'estuviera', 'estuvieras', 'estuvi\u00e9ramos', 'estuvierais', 'estuvieran', 'estuviese', 'estuvieses', 'estuvi\u00e9semos', 'estuvieseis', 'estuviesen', 'estando', 'estado', 'estada', 'estados', 'estadas', 'estad', 'he', 'has', 'ha', 'hemos', 'hab\u00e9is', 'han', 'haya', 'hayas', 'hayamos', 'hay\u00e1is', 'hayan', 'habr\u00e9', 'habr\u00e1s', 'habr\u00e1', 'habremos', 'habr\u00e9is', 'habr\u00e1n', 'habr\u00eda', 'habr\u00edas', 'habr\u00edamos', 'habr\u00edais', 'habr\u00edan', 'hab\u00eda', 'hab\u00edas', 'hab\u00edamos', 'hab\u00edais', 'hab\u00edan', 'hube', 'hubiste', 'hubo', 'hubimos', 'hubisteis', 'hubieron', 'hubiera', 'hubieras', 'hubi\u00e9ramos', 'hubierais', 'hubieran', 'hubiese', 'hubieses', 'hubi\u00e9semos', 'hubieseis', 'hubiesen', 'habiendo', 'habido', 'habida', 'habidos', 'habidas', 'soy', 'eres', 'es', 'somos', 'sois', 'son', 'sea', 'seas', 'seamos', 'se\u00e1is', 'sean', 'ser\u00e9', 'ser\u00e1s', 'ser\u00e1', 'seremos', 'ser\u00e9is', 'ser\u00e1n', 'ser\u00eda', 'ser\u00edas', 'ser\u00edamos', 'ser\u00edais', 'ser\u00edan', 'era', 'eras', '\u00e9ramos', 'erais', 'eran', 'fui', 'fuiste', 'fue', 'fuimos', 'fuisteis', 'fueron', 'fuera', 'fueras', 'fu\u00e9ramos', 'fuerais', 'fueran', 'fuese', 'fueses', 'fu\u00e9semos', 'fueseis', 'fuesen', 'sintiendo', 'sentido', 'sentida', 'sentidos', 'sentidas', 'siente', 'sentid', 'tengo', 'tienes', 'tiene', 'tenemos', 'ten\u00e9is', 'tienen', 'tenga', 'tengas', 'tengamos', 'teng\u00e1is', 'tengan', 'tendr\u00e9', 'tendr\u00e1s', 'tendr\u00e1', 'tendremos', 'tendr\u00e9is', 'tendr\u00e1n', 'tendr\u00eda', 'tendr\u00edas', 'tendr\u00edamos', 'tendr\u00edais', 'tendr\u00edan', 'ten\u00eda', 'ten\u00edas', 'ten\u00edamos', 'ten\u00edais', 'ten\u00edan', 'tuve', 'tuviste', 'tuvo', 'tuvimos', 'tuvisteis', 'tuvieron', 'tuviera', 'tuvieras', 'tuvi\u00e9ramos', 'tuvierais', 'tuvieran', 'tuviese', 'tuvieses', 'tuvi\u00e9semos', 'tuvieseis', 'tuviesen', 'teniendo', 'tenido', 'tenida', 'tenidos', 'tenidas', 'tened', 'NaN']\n\nstop.append('NaN')\nprint(stop)", "execution_count": 11, "outputs": [{"output_type": "stream", "text": "['de', 'la', 'que', 'el', 'en', 'y', 'a', 'los', 'del', 'se', 'las', 'por', 'un', 'para', 'con', 'no', 'una', 'su', 'al', 'lo', 'como', 'm\u00e1s', 'pero', 'sus', 'le', 'ya', 'o', 'este', 's\u00ed', 'porque', 'esta', 'entre', 'cuando', 'muy', 'sin', 'sobre', 'tambi\u00e9n', 'me', 'hasta', 'hay', 'donde', 'quien', 'desde', 'todo', 'nos', 'durante', 'todos', 'uno', 'les', 'ni', 'contra', 'otros', 'ese', 'eso', 'ante', 'ellos', 'e', 'esto', 'm\u00ed', 'antes', 'algunos', 'qu\u00e9', 'unos', 'yo', 'otro', 'otras', 'otra', '\u00e9l', 'tanto', 'esa', 'estos', 'mucho', 'quienes', 'nada', 'muchos', 'cual', 'poco', 'ella', 'estar', 'estas', 'algunas', 'algo', 'nosotros', 'mi', 'mis', 't\u00fa', 'te', 'ti', 'tu', 'tus', 'ellas', 'nosotras', 'vosotros', 'vosotras', 'os', 'm\u00edo', 'm\u00eda', 'm\u00edos', 'm\u00edas', 'tuyo', 'tuya', 'tuyos', 'tuyas', 'suyo', 'suya', 'suyos', 'suyas', 'nuestro', 'nuestra', 'nuestros', 'nuestras', 'vuestro', 'vuestra', 'vuestros', 'vuestras', 'esos', 'esas', 'estoy', 'est\u00e1s', 'est\u00e1', 'estamos', 'est\u00e1is', 'est\u00e1n', 'est\u00e9', 'est\u00e9s', 'estemos', 'est\u00e9is', 'est\u00e9n', 'estar\u00e9', 'estar\u00e1s', 'estar\u00e1', 'estaremos', 'estar\u00e9is', 'estar\u00e1n', 'estar\u00eda', 'estar\u00edas', 'estar\u00edamos', 'estar\u00edais', 'estar\u00edan', 'estaba', 'estabas', 'est\u00e1bamos', 'estabais', 'estaban', 'estuve', 'estuviste', 'estuvo', 'estuvimos', 'estuvisteis', 'estuvieron', 'estuviera', 'estuvieras', 'estuvi\u00e9ramos', 'estuvierais', 'estuvieran', 'estuviese', 'estuvieses', 'estuvi\u00e9semos', 'estuvieseis', 'estuviesen', 'estando', 'estado', 'estada', 'estados', 'estadas', 'estad', 'he', 'has', 'ha', 'hemos', 'hab\u00e9is', 'han', 'haya', 'hayas', 'hayamos', 'hay\u00e1is', 'hayan', 'habr\u00e9', 'habr\u00e1s', 'habr\u00e1', 'habremos', 'habr\u00e9is', 'habr\u00e1n', 'habr\u00eda', 'habr\u00edas', 'habr\u00edamos', 'habr\u00edais', 'habr\u00edan', 'hab\u00eda', 'hab\u00edas', 'hab\u00edamos', 'hab\u00edais', 'hab\u00edan', 'hube', 'hubiste', 'hubo', 'hubimos', 'hubisteis', 'hubieron', 'hubiera', 'hubieras', 'hubi\u00e9ramos', 'hubierais', 'hubieran', 'hubiese', 'hubieses', 'hubi\u00e9semos', 'hubieseis', 'hubiesen', 'habiendo', 'habido', 'habida', 'habidos', 'habidas', 'soy', 'eres', 'es', 'somos', 'sois', 'son', 'sea', 'seas', 'seamos', 'se\u00e1is', 'sean', 'ser\u00e9', 'ser\u00e1s', 'ser\u00e1', 'seremos', 'ser\u00e9is', 'ser\u00e1n', 'ser\u00eda', 'ser\u00edas', 'ser\u00edamos', 'ser\u00edais', 'ser\u00edan', 'era', 'eras', '\u00e9ramos', 'erais', 'eran', 'fui', 'fuiste', 'fue', 'fuimos', 'fuisteis', 'fueron', 'fuera', 'fueras', 'fu\u00e9ramos', 'fuerais', 'fueran', 'fuese', 'fueses', 'fu\u00e9semos', 'fueseis', 'fuesen', 'sintiendo', 'sentido', 'sentida', 'sentidos', 'sentidas', 'siente', 'sentid', 'tengo', 'tienes', 'tiene', 'tenemos', 'ten\u00e9is', 'tienen', 'tenga', 'tengas', 'tengamos', 'teng\u00e1is', 'tengan', 'tendr\u00e9', 'tendr\u00e1s', 'tendr\u00e1', 'tendremos', 'tendr\u00e9is', 'tendr\u00e1n', 'tendr\u00eda', 'tendr\u00edas', 'tendr\u00edamos', 'tendr\u00edais', 'tendr\u00edan', 'ten\u00eda', 'ten\u00edas', 'ten\u00edamos', 'ten\u00edais', 'ten\u00edan', 'tuve', 'tuviste', 'tuvo', 'tuvimos', 'tuvisteis', 'tuvieron', 'tuviera', 'tuvieras', 'tuvi\u00e9ramos', 'tuvierais', 'tuvieran', 'tuviese', 'tuvieses', 'tuvi\u00e9semos', 'tuvieseis', 'tuviesen', 'teniendo', 'tenido', 'tenida', 'tenidos', 'tenidas', 'tened', 'NaN', 'NaN']\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "\ndf[\"Review Content_nstopwords\"] = df[\"Review Content\"].apply(lambda word: len([x for x in str(word).split(\" \") if x in stop]))\ndf[[\"Review Content\",\"Review Content_nstopwords\"]].sort_values(by = \"Review Content_nstopwords\",ascending = False).head()\n\n", "execution_count": 12, "outputs": [{"output_type": "execute_result", "execution_count": 12, "data": {"text/plain": "                                         Review Content  \\\n1763  Entrega: Dentro de los estimado.  Comunicacion...   \n4143  Entrega: Dentro de los estimado.  Comunicacion...   \n1758  Entrega: Dentro de los estimado.  Comunicacion...   \n4158  Entrega: Dentro de los estimado.  Comunicacion...   \n1767  Entrega: Dentro de los estimado.  Comunicacion...   \n\n      Review Content_nstopwords  \n1763                        113  \n4143                        113  \n1758                        113  \n4158                        113  \n1767                        113  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Review Content</th>\n      <th>Review Content_nstopwords</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1763</th>\n      <td>Entrega: Dentro de los estimado.  Comunicacion...</td>\n      <td>113</td>\n    </tr>\n    <tr>\n      <th>4143</th>\n      <td>Entrega: Dentro de los estimado.  Comunicacion...</td>\n      <td>113</td>\n    </tr>\n    <tr>\n      <th>1758</th>\n      <td>Entrega: Dentro de los estimado.  Comunicacion...</td>\n      <td>113</td>\n    </tr>\n    <tr>\n      <th>4158</th>\n      <td>Entrega: Dentro de los estimado.  Comunicacion...</td>\n      <td>113</td>\n    </tr>\n    <tr>\n      <th>1767</th>\n      <td>Entrega: Dentro de los estimado.  Comunicacion...</td>\n      <td>113</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "df[[\"Review Content\",\"Review Content_nstopwords\"]].sort_values(by = \"Review Content_nstopwords\",ascending = True).head()", "execution_count": 13, "outputs": [{"output_type": "execute_result", "execution_count": 13, "data": {"text/plain": "                                         Review Content  \\\n3649  JUSTO A LOS DOS MESES DE COMPRADO, EL CONTROL ...   \n2445                                                NaN   \n4493                                                NaN   \n4495                                                NaN   \n4496                                                NaN   \n\n      Review Content_nstopwords  \n3649                          0  \n2445                          0  \n4493                          0  \n4495                          0  \n4496                          0  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Review Content</th>\n      <th>Review Content_nstopwords</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3649</th>\n      <td>JUSTO A LOS DOS MESES DE COMPRADO, EL CONTROL ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2445</th>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4493</th>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4495</th>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4496</th>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "df[\"Review Content_ndigits\"] = df[\"Review Content\"].apply(lambda x: len([x for x in str(x).split() if x.isdigit()]))\ndf[[\"Review Content\",\"Review Content_ndigits\"]].sort_values(by = \"Review Content_ndigits\",ascending = False).head()", "execution_count": 14, "outputs": [{"output_type": "execute_result", "execution_count": 14, "data": {"text/plain": "                                         Review Content  \\\n486   So many things are not as described on this co...   \n1478  So many things are not as described on this co...   \n1474  So many things are not as described on this co...   \n482   So many things are not as described on this co...   \n3858  So many things are not as described on this co...   \n\n      Review Content_ndigits  \n486                       10  \n1478                      10  \n1474                      10  \n482                       10  \n3858                      10  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Review Content</th>\n      <th>Review Content_ndigits</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>486</th>\n      <td>So many things are not as described on this co...</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>1478</th>\n      <td>So many things are not as described on this co...</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>1474</th>\n      <td>So many things are not as described on this co...</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>482</th>\n      <td>So many things are not as described on this co...</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>3858</th>\n      <td>So many things are not as described on this co...</td>\n      <td>10</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "#Number of short_description with lots of Upper words\ndf[\"Review Content_nupper\"] = df[\"Review Content\"].apply((lambda word: len([x for x in str(word).split() if x.isupper()])))\ndf[[\"Review Content\",\"Review Content_nupper\"]].sort_values(by = \"Review Content_nupper\",ascending = False).head()", "execution_count": 15, "outputs": [{"output_type": "execute_result", "execution_count": 15, "data": {"text/plain": "                                         Review Content  Review Content_nupper\n298   JUSTO A LOS DOS MESES DE COMPRADO, EL CONTROL ...                     35\n1269  JUSTO A LOS DOS MESES DE COMPRADO, EL CONTROL ...                     35\n1234  JUSTO A LOS DOS MESES DE COMPRADO, EL CONTROL ...                     35\n277   JUSTO A LOS DOS MESES DE COMPRADO, EL CONTROL ...                     35\n3682  JUSTO A LOS DOS MESES DE COMPRADO, EL CONTROL ...                     35", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Review Content</th>\n      <th>Review Content_nupper</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>298</th>\n      <td>JUSTO A LOS DOS MESES DE COMPRADO, EL CONTROL ...</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>1269</th>\n      <td>JUSTO A LOS DOS MESES DE COMPRADO, EL CONTROL ...</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>1234</th>\n      <td>JUSTO A LOS DOS MESES DE COMPRADO, EL CONTROL ...</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>277</th>\n      <td>JUSTO A LOS DOS MESES DE COMPRADO, EL CONTROL ...</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>3682</th>\n      <td>JUSTO A LOS DOS MESES DE COMPRADO, EL CONTROL ...</td>\n      <td>35</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "## NLP Treatment's\nThe most common treatments we use are transforming into lower case, some times removing dates from data, remove stop words, lemmatizing, replacing accents (in this case already did in data extraction nb), stemming (personally I prefer only using lemma)"}, {"metadata": {}, "cell_type": "code", "source": "#lets clone into new column\ndf['Tokens_Review_Content'] = df['Review Content']", "execution_count": 16, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#lower everything\ndf['Tokens_Review_Content'] = df['Tokens_Review_Content'].apply(lambda x: str(x).lower())\n", "execution_count": 17, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#lets start replacing some characters we found above\ndf['Tokens_Review_Content'] = df['Tokens_Review_Content'].str.replace(' / ',' ')\ndf['Tokens_Review_Content'] = df['Tokens_Review_Content'].str.replace('[^\\w\\s]',' ')\ndf['Tokens_Review_Content'] = df['Tokens_Review_Content'].str.replace('  ',' ')", "execution_count": 18, "outputs": [{"output_type": "stream", "text": "/tmp/ipykernel_45845/2756120894.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n  df['Tokens_Review_Content'] = df['Tokens_Review_Content'].str.replace('[^\\w\\s]',' ')\n", "name": "stderr"}]}, {"metadata": {}, "cell_type": "code", "source": "#normalize for ascii utf8\ndf['Review Content'] = df['Review Content'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\ndf['Tokens_Review_Content'] = df['Tokens_Review_Content'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n", "execution_count": 19, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Removal of stop word\ndf['Tokens_Review_Content'] = df['Tokens_Review_Content'].apply(lambda x: ' '.join(x for x in x.split() if x not in stop))\n", "execution_count": 20, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "let's use spacy for lemmatization\n<br>\nis a more effective option than stemming because it converts the word into its root word, rather than just stripping the suffices. It makes use of the vocabulary and does a morphological analysis to obtain the root word. Therefore, we usually prefer using lemmatization over stemming."}, {"metadata": {}, "cell_type": "code", "source": "import spacy\nimport es_core_news_sm\nnlp = es_core_news_sm.load()\n\ndf['Tokens_Review_Content'] = df['Tokens_Review_Content'].apply(lambda x: ' '.join([myword.lemma_ for myword in nlp(x)]))\n", "execution_count": 21, "outputs": [{"output_type": "stream", "text": "2022-02-24 18:58:51.751902: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ibm/connectors/dsdriver/dsdriver/lib:/opt/ibm/connectors/others-db-drivers/oracle/lib:/opt/ibm/jdk/jre/lib/architecture/server:/opt/ibm/jdk/jre/lib/architecture/:/usr/local/lib:/lib64\n2022-02-24 18:58:51.751942: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n", "name": "stderr"}]}, {"metadata": {}, "cell_type": "code", "source": "## Importing Textblob package\n#fro0m textblob import TextBlob\n\n#df['Tokens_Review_Content'] =  df['Tokens_Review_Content'].apply(lambda x: TextBlob(x).words)\ndf['Tokens_Review_Content'].tail(10)", "execution_count": 22, "outputs": [{"output_type": "execute_result", "execution_count": 22, "data": {"text/plain": "6437    perro raza mediano verdad pense ir desaparecer...\n6438    buen articulo cachorro encantar especialmente ...\n6439    cachorro schnauzer miniatura etapa querer mord...\n6440    primero mano veiar si ir resistir prestir pelo...\n6441    salchichaber mucho energiar decidir dar \u00e9l 4 j...\n6442    kit venir completo tal venir imagen deber deci...\n6443    perritir muerde muchisimo tiro dos diente carn...\n6444    perro raza mediano verdad pense ir desaparecer...\n6445    buen articulo cachorro encantar especialmente ...\n6446    producto utilizar juguete perrito gusto ratito...\nName: Tokens_Review_Content, dtype: object"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Sentiment Analysis\nWe used LinCE dataset for training multilingual BERT model using huggingface transformers. LinCE has four language mixed data. We took three of it spanish-english, hindi-english and nepali-english. Hope we will train and add other language and task too."}, {"metadata": {}, "cell_type": "code", "source": "#!pip install codeswitch", "execution_count": 23, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n# declare tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"sagorsarker/codeswitch-spaeng-sentiment-analysis-lince\")\n# declare model\nmodel = AutoModelForSequenceClassification.from_pretrained(\"sagorsarker/codeswitch-spaeng-sentiment-analysis-lince\")\n", "execution_count": 24, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df['Review Content'] = df['Review Content'].str.replace(' / ',' ')\ndf['Review Content'] = df['Review Content'].str.replace('[^\\w\\s]',' ')\ndf['Review Content'] = df['Review Content'].str.replace('  ',' ')", "execution_count": 25, "outputs": [{"output_type": "stream", "text": "/tmp/ipykernel_45845/1026782208.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n  df['Review Content'] = df['Review Content'].str.replace('[^\\w\\s]',' ')\n", "name": "stderr"}]}, {"metadata": {}, "cell_type": "code", "source": "#!pip install pysentimient", "execution_count": 26, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from pysentimiento import create_analyzer\nanalyzer = create_analyzer(task=\"sentiment\", lang=\"es\")", "execution_count": 27, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# now lets apply our model to the data\n\ndf['Sentiment'] =  df['Review Content'].apply(lambda x: analyzer.predict(str(x)))", "execution_count": 28, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df.head()", "execution_count": 29, "outputs": [{"output_type": "execute_result", "execution_count": 29, "data": {"text/plain": "  Review Author                                     Review Content  Stars  \\\n0        Sydney  Tolles Halsband super gut verarbeitet und die ...    0.0   \n1        Sydney  Tolles Halsband super gut verarbeitet und die ...    0.0   \n2  Carmen Heger  Ich bin total verliebt in diese Halsbander Mit...    0.0   \n3        Sydney  Tolles Halsband super gut verarbeitet und die ...    0.0   \n4  Carmen Heger  Ich bin total verliebt in diese Halsbander Mit...    0.0   \n\n   Review Content_nword  Review Content_nchars  Review Content_nstopwords  \\\n0                    93                  566.0                          2   \n1                    93                  566.0                          2   \n2                    55                  336.0                          0   \n3                    93                  566.0                          2   \n4                    55                  336.0                          0   \n\n   Review Content_ndigits  Review Content_nupper  \\\n0                       0                      0   \n1                       0                      0   \n2                       0                      3   \n3                       0                      0   \n4                       0                      3   \n\n                               Tokens_Review_Content  \\\n0  toll halsband super gut verarbeitet und die mo...   \n1  toll halsband super gut verarbeitet und die mo...   \n2  ich bin total verliebt in dar halsbander mit d...   \n3  toll halsband super gut verarbeitet und die mo...   \n4  ich bin total verliebt in dar halsbander mit d...   \n\n                                           Sentiment  \n0  AnalyzerOutput(output=NEU, probas={NEU: 0.717,...  \n1  AnalyzerOutput(output=NEU, probas={NEU: 0.717,...  \n2  AnalyzerOutput(output=NEU, probas={NEU: 0.560,...  \n3  AnalyzerOutput(output=NEU, probas={NEU: 0.717,...  \n4  AnalyzerOutput(output=NEU, probas={NEU: 0.560,...  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Review Author</th>\n      <th>Review Content</th>\n      <th>Stars</th>\n      <th>Review Content_nword</th>\n      <th>Review Content_nchars</th>\n      <th>Review Content_nstopwords</th>\n      <th>Review Content_ndigits</th>\n      <th>Review Content_nupper</th>\n      <th>Tokens_Review_Content</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Sydney</td>\n      <td>Tolles Halsband super gut verarbeitet und die ...</td>\n      <td>0.0</td>\n      <td>93</td>\n      <td>566.0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>toll halsband super gut verarbeitet und die mo...</td>\n      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.717,...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sydney</td>\n      <td>Tolles Halsband super gut verarbeitet und die ...</td>\n      <td>0.0</td>\n      <td>93</td>\n      <td>566.0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>toll halsband super gut verarbeitet und die mo...</td>\n      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.717,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Carmen Heger</td>\n      <td>Ich bin total verliebt in diese Halsbander Mit...</td>\n      <td>0.0</td>\n      <td>55</td>\n      <td>336.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>ich bin total verliebt in dar halsbander mit d...</td>\n      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.560,...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Sydney</td>\n      <td>Tolles Halsband super gut verarbeitet und die ...</td>\n      <td>0.0</td>\n      <td>93</td>\n      <td>566.0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>toll halsband super gut verarbeitet und die mo...</td>\n      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.717,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Carmen Heger</td>\n      <td>Ich bin total verliebt in diese Halsbander Mit...</td>\n      <td>0.0</td>\n      <td>55</td>\n      <td>336.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>ich bin total verliebt in dar halsbander mit d...</td>\n      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.560,...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "df['Probs'] = df['Sentiment']\nneg=[]\nneu=[]\npos=[]\navg =[]\noutput = []\n\nfor index, row in df.iterrows():\n    value = row['Probs']\n    value = str(value.probas.values())\n    value = value.replace('dict_values([','')\n    value = value.replace('])','')\n    value = value.replace(' ','')\n    neg.append(value.split(\",\")[0])\n    neu.append(value.split(\",\")[1])\n    pos.append(value.split(\",\")[2])\n    avg.append((float(value.split(\",\")[1])-float(value.split(\",\")[0])+float(value.split(\",\")[2])))\n    res = row['Probs']\n    res = str(res.output)\n    output.append(res)\n\n\n\ndf['Sent_Negative'] = neg\ndf['Sent_Neutral'] = neu\ndf['Sent_Positive'] = pos\ndf['Sent_Average'] = avg\ndf['Sentiment Output'] = output\n\n\ndf.head()", "execution_count": 30, "outputs": [{"output_type": "execute_result", "execution_count": 30, "data": {"text/plain": "  Review Author                                     Review Content  Stars  \\\n0        Sydney  Tolles Halsband super gut verarbeitet und die ...    0.0   \n1        Sydney  Tolles Halsband super gut verarbeitet und die ...    0.0   \n2  Carmen Heger  Ich bin total verliebt in diese Halsbander Mit...    0.0   \n3        Sydney  Tolles Halsband super gut verarbeitet und die ...    0.0   \n4  Carmen Heger  Ich bin total verliebt in diese Halsbander Mit...    0.0   \n\n   Review Content_nword  Review Content_nchars  Review Content_nstopwords  \\\n0                    93                  566.0                          2   \n1                    93                  566.0                          2   \n2                    55                  336.0                          0   \n3                    93                  566.0                          2   \n4                    55                  336.0                          0   \n\n   Review Content_ndigits  Review Content_nupper  \\\n0                       0                      0   \n1                       0                      0   \n2                       0                      3   \n3                       0                      0   \n4                       0                      3   \n\n                               Tokens_Review_Content  \\\n0  toll halsband super gut verarbeitet und die mo...   \n1  toll halsband super gut verarbeitet und die mo...   \n2  ich bin total verliebt in dar halsbander mit d...   \n3  toll halsband super gut verarbeitet und die mo...   \n4  ich bin total verliebt in dar halsbander mit d...   \n\n                                           Sentiment  \\\n0  AnalyzerOutput(output=NEU, probas={NEU: 0.717,...   \n1  AnalyzerOutput(output=NEU, probas={NEU: 0.717,...   \n2  AnalyzerOutput(output=NEU, probas={NEU: 0.560,...   \n3  AnalyzerOutput(output=NEU, probas={NEU: 0.717,...   \n4  AnalyzerOutput(output=NEU, probas={NEU: 0.560,...   \n\n                                               Probs        Sent_Negative  \\\n0  AnalyzerOutput(output=NEU, probas={NEU: 0.717,...  0.22109386324882507   \n1  AnalyzerOutput(output=NEU, probas={NEU: 0.717,...  0.22109386324882507   \n2  AnalyzerOutput(output=NEU, probas={NEU: 0.560,...  0.35247623920440674   \n3  AnalyzerOutput(output=NEU, probas={NEU: 0.717,...  0.22109386324882507   \n4  AnalyzerOutput(output=NEU, probas={NEU: 0.560,...  0.35247623920440674   \n\n         Sent_Neutral        Sent_Positive  Sent_Average Sentiment Output  \n0  0.7169512510299683  0.06195483356714249      0.557812              NEU  \n1  0.7169512510299683  0.06195483356714249      0.557812              NEU  \n2  0.5600517988204956  0.08747199177742004      0.295048              NEU  \n3  0.7169512510299683  0.06195483356714249      0.557812              NEU  \n4  0.5600517988204956  0.08747199177742004      0.295048              NEU  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Review Author</th>\n      <th>Review Content</th>\n      <th>Stars</th>\n      <th>Review Content_nword</th>\n      <th>Review Content_nchars</th>\n      <th>Review Content_nstopwords</th>\n      <th>Review Content_ndigits</th>\n      <th>Review Content_nupper</th>\n      <th>Tokens_Review_Content</th>\n      <th>Sentiment</th>\n      <th>Probs</th>\n      <th>Sent_Negative</th>\n      <th>Sent_Neutral</th>\n      <th>Sent_Positive</th>\n      <th>Sent_Average</th>\n      <th>Sentiment Output</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Sydney</td>\n      <td>Tolles Halsband super gut verarbeitet und die ...</td>\n      <td>0.0</td>\n      <td>93</td>\n      <td>566.0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>toll halsband super gut verarbeitet und die mo...</td>\n      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.717,...</td>\n      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.717,...</td>\n      <td>0.22109386324882507</td>\n      <td>0.7169512510299683</td>\n      <td>0.06195483356714249</td>\n      <td>0.557812</td>\n      <td>NEU</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sydney</td>\n      <td>Tolles Halsband super gut verarbeitet und die ...</td>\n      <td>0.0</td>\n      <td>93</td>\n      <td>566.0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>toll halsband super gut verarbeitet und die mo...</td>\n      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.717,...</td>\n      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.717,...</td>\n      <td>0.22109386324882507</td>\n      <td>0.7169512510299683</td>\n      <td>0.06195483356714249</td>\n      <td>0.557812</td>\n      <td>NEU</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Carmen Heger</td>\n      <td>Ich bin total verliebt in diese Halsbander Mit...</td>\n      <td>0.0</td>\n      <td>55</td>\n      <td>336.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>ich bin total verliebt in dar halsbander mit d...</td>\n      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.560,...</td>\n      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.560,...</td>\n      <td>0.35247623920440674</td>\n      <td>0.5600517988204956</td>\n      <td>0.08747199177742004</td>\n      <td>0.295048</td>\n      <td>NEU</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Sydney</td>\n      <td>Tolles Halsband super gut verarbeitet und die ...</td>\n      <td>0.0</td>\n      <td>93</td>\n      <td>566.0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>toll halsband super gut verarbeitet und die mo...</td>\n      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.717,...</td>\n      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.717,...</td>\n      <td>0.22109386324882507</td>\n      <td>0.7169512510299683</td>\n      <td>0.06195483356714249</td>\n      <td>0.557812</td>\n      <td>NEU</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Carmen Heger</td>\n      <td>Ich bin total verliebt in diese Halsbander Mit...</td>\n      <td>0.0</td>\n      <td>55</td>\n      <td>336.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>ich bin total verliebt in dar halsbander mit d...</td>\n      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.560,...</td>\n      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.560,...</td>\n      <td>0.35247623920440674</td>\n      <td>0.5600517988204956</td>\n      <td>0.08747199177742004</td>\n      <td>0.295048</td>\n      <td>NEU</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "### Sentiment Analysis Views"}, {"metadata": {}, "cell_type": "code", "source": "sentiment_group = df.groupby(\"Sentiment Output\")\ndf[\"Sent_Negative\"]=df[\"Sent_Negative\"].astype(float)\ndf[\"Sent_Neutral\"]=df[\"Sent_Neutral\"].astype(float)\ndf[\"Sent_Positive\"]=df[\"Sent_Positive\"].astype(float)", "execution_count": 35, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df.plot(x=\"Sentiment Output\", y=[\"Sent_Negative\", \"Sent_Neutral\", \"Sent_Positive\"], kind=\"bar\")", "execution_count": 36, "outputs": [{"output_type": "execute_result", "execution_count": 36, "data": {"text/plain": "<AxesSubplot:xlabel='Sentiment Output'>"}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "<Figure size 432x288 with 1 Axes>", "image/png": "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\n"}, "metadata": {"needs_background": "light"}}]}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"interpreter": {"hash": "068f29a5db6983e2a2b94cc2ae84a4c07cda7a391da3c6e0ffd8c0fd5119eeaa"}, "kernelspec": {"name": "python38", "display_name": "Python 3.8 with Spark", "language": "python3"}, "language_info": {"name": "python", "version": "3.8.12", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 2}